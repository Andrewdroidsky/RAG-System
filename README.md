# RAG System

A powerful Retrieval-Augmented Generation system for document processing and querying.

## Features / –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üìÑ Multi-format support: PDF, DOCX, TXT, XLSX / –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤: PDF, DOCX, TXT, XLSX
- üîç Accurate citations with page/section references / –¢–æ—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Ä–∞–∑–¥–µ–ª—ã
- üíæ Unlimited document capacity using IndexedDB / –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –µ–º–∫–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ IndexedDB
- üí∞ Token counting and cost estimation / –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
- ‚ö° Batch processing for optimal performance / –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- üéØ Precise source attribution in responses / –¢–æ—á–Ω–∞—è –∞—Ç—Ä–∏–±—É—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –æ—Ç–≤–µ—Ç–∞—Ö
- üåê Bilingual support (Russian/English) / –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–≤—É—Ö —è–∑—ã–∫–æ–≤ (—Ä—É—Å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
- üí¨ Chat interface with conversation history / –ß–∞—Ç-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤
- üèóÔ∏è Two-level RAG architecture for better accuracy / –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è RAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏

## Architecture / –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### Two-Level RAG System / –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è RAG —Å–∏—Å—Ç–µ–º–∞

This system implements an innovative **two-level RAG architecture** that solves the fundamental chunking problem in traditional RAG systems:

–≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—É—é **–¥–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—É—é RAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É**, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ—à–∞–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É —á–∞–Ω–∫–∏–Ω–≥–∞ –≤ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö RAG —Å–∏—Å—Ç–µ–º–∞—Ö:

#### The Chunking Problem / –ü—Ä–æ–±–ª–µ–º–∞ —á–∞–Ω–∫–∏–Ω–≥–∞
Traditional RAG systems face a dilemma:
- **Small chunks** enable efficient search but lose context and lead to inaccurate references
- **Large chunks** preserve context but make search inefficient and expensive

–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ RAG —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–ª–∫–∏–≤–∞—é—Ç—Å—è —Å –¥–∏–ª–µ–º–º–æ–π:
- **–ú–∞–ª–µ–Ω—å–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã** –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫, –Ω–æ —Ç–µ—Ä—è—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –Ω–µ—Ç–æ—á–Ω—ã–º —Å—Å—ã–ª–∫–∞–º
- **–ë–æ–ª—å—à–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã** —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–æ –¥–µ–ª–∞—é—Ç –ø–æ–∏—Å–∫ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –∏ –¥–æ—Ä–æ–≥–∏–º

#### Our Solution: Dual Storage / –ù–∞—à–µ —Ä–µ—à–µ–Ω–∏–µ: –¥–≤–æ–π–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ
1. **Level 1: Full Pages** - Complete pages stored for context and accurate referencing
2. **Level 2: Optimized Chunks** - Small chunks (1000 tokens) for efficient semantic search

1. **–£—Ä–æ–≤–µ–Ω—å 1: –ü–æ–ª–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã** - –ü–æ–ª–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ç–æ—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
2. **–£—Ä–æ–≤–µ–Ω—å 2: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã** - –ú–∞–ª–µ–Ω—å–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (1000 —Ç–æ–∫–µ–Ω–æ–≤) –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞

#### How It Works / –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
1. **Document Processing**: Documents are split into both full pages and searchable chunks
2. **Two-Stage Search**:
   - Find relevant pages using averaged chunk similarities
   - Extract chunks only from relevant pages
3. **Context Building**: Provide AI with both full pages (context) and relevant chunks (details)
4. **Accurate References**: AI can reference complete pages, not just fragments

1. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤**: –î–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ –ø–æ–ª–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
2. **–î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–∏—Å–∫**:
   - –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—É—é –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
   - –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
3. **–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞**: –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º –ò–ò –ø–æ–ª–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∫–æ–Ω—Ç–µ–∫—Å—Ç) –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (–¥–µ—Ç–∞–ª–∏)
4. **–¢–æ—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏**: –ò–ò –º–æ–∂–µ—Ç —Å—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ –ø–æ–ª–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã

### Embeddings & Vector Search / –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫

**What are Embeddings? / –ß—Ç–æ —Ç–∞–∫–æ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏?**

Embeddings are numerical vectors (arrays of numbers) that represent the semantic meaning of text. Similar concepts have similar vector representations, enabling semantic search.

–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ - —ç—Ç–æ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã (–º–∞—Å—Å–∏–≤—ã —á–∏—Å–µ–ª), –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞. –ü–æ—Ö–æ–∂–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏–º–µ—é—Ç –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫.

**Example / –ü—Ä–∏–º–µ—Ä:**
- "cat" and "kitten" have similar embeddings / "–∫–æ—Ç" –∏ "–∫–æ—Ç–µ–Ω–æ–∫" –∏–º–µ—é—Ç –ø–æ—Ö–æ–∂–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
- "car" and "vehicle" have similar embeddings / "–º–∞—à–∏–Ω–∞" –∏ "–∞–≤—Ç–æ–º–æ–±–∏–ª—å" –∏–º–µ—é—Ç –ø–æ—Ö–æ–∂–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
- "cat" and "car" have different embeddings / "–∫–æ—Ç" –∏ "–º–∞—à–∏–Ω–∞" –∏–º–µ—é—Ç —Ä–∞–∑–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏

**How Vector Search Works / –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫:**
1. Convert user question to embedding vector / –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
2. Calculate similarity (cosine similarity) between question and all document chunks / –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ö–æ–∂–µ—Å—Ç—å (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å) –º–µ–∂–¥—É –≤–æ–ø—Ä–æ—Å–æ–º –∏ –≤—Å–µ–º–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
3. Return most similar chunks as relevant content / –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–∞–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç

**Benefits / –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- Understands context and meaning, not just keywords / –ü–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–º—ã—Å–ª, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
- Finds relevant information even with different wording / –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–∞–∂–µ –ø—Ä–∏ —Ä–∞–∑–Ω–æ–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ
- Enables semantic search across multiple languages / –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö

## Setup

1. **Install dependencies:**
   ```bash
   npm install
   ```

2. **Configure OpenAI API Key:**

   Edit `.env.local` and replace the placeholder with your actual OpenAI API key:
   ```
   NEXT_PUBLIC_OPENAI_API_KEY=sk-your-actual-openai-api-key-here
   ```

3. **Run the development server:**
   ```bash
   npm run dev
   ```

4. **Build for production:**
   ```bash
   npm run build
   ```

## Usage

1. Open the application in your browser
2. Upload documents (PDF, DOCX, TXT, XLSX)
3. Wait for processing and embedding creation
4. Ask questions about your documents
5. Get answers with accurate source citations

## Deployment

The application is configured for static export and can be deployed to Netlify, Vercel, or any static hosting service.

## Security Note

The OpenAI API key is embedded in the client-side application. For production use with untrusted users, consider implementing a backend API to secure the key.